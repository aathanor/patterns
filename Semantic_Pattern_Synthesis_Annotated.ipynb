{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ba4c21",
   "metadata": {},
   "source": [
    "# Semantic Pattern Synthesis\n",
    "This notebook synthesizes experiments analyzing the topological and functional structure of contextual meaning. We focus on the verb **'run'**, examining BERT trajectories, curvature, clustering, and functional mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a41db76",
   "metadata": {},
   "source": [
    "## 1. Load contextual sentences\n",
    "We define 48 contextual uses of *'run'* evenly across four semantic functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b80f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    # descriptive (12)\n",
    "    \"She likes to run early in the morning before work.\",\n",
    "    \"The marathon runner collapsed after a grueling 26-mile run.\",\n",
    "    \"The river runs along the eastern border.\",\n",
    "    \"The software update runs automatically.\",\n",
    "    \"His nose began to run during the allergy season.\",\n",
    "    \"The ink began to run in the rain.\",\n",
    "    \"We saw a deer run across the highway at dusk.\",\n",
    "    \"The children ran through the field chasing butterflies.\",\n",
    "    \"The mountain stream runs fast in spring.\",\n",
    "    \"The play ran for three consecutive seasons.\",\n",
    "    \"They ran diagnostics to isolate the error.\",\n",
    "    \"She ran her fingers along the dusty shelf.\",\n",
    "    # evaluative (12)\n",
    "    \"That joke is starting to run thin.\",\n",
    "    \"The show has had a good run but it's time to end.\",\n",
    "    \"Don‚Äôt let your temper run away with you.\",\n",
    "    \"The campaign is running out of steam.\",\n",
    "    \"He let the story run its course.\",\n",
    "    \"This film had a limited theatrical run.\",\n",
    "    \"That rumor ran rampant on social media.\",\n",
    "    \"He was caught in a run of bad luck.\",\n",
    "    \"He‚Äôs running behind schedule again.\",\n",
    "    \"She‚Äôs running on empty after a tough week.\",\n",
    "    \"The idea ran against conventional wisdom.\",\n",
    "    \"His excuses are beginning to run thin.\",\n",
    "    # narrative (12)\n",
    "    \"He ran into trouble with the tax authorities.\",\n",
    "    \"She ran the numbers twice before presenting them.\",\n",
    "    \"The suspect tried to run from the scene.\",\n",
    "    \"We did a test run before the final performance.\",\n",
    "    \"The faucet was left on and water began to run.\",\n",
    "    \"She screamed and began to run down the street.\",\n",
    "    \"He let his imagination run wild.\",\n",
    "    \"They ran a tight ship in that department.\",\n",
    "    \"They run tests on samples before publishing results.\",\n",
    "    \"Let‚Äôs run through the list one more time.\",\n",
    "    \"He ran his hand over the sculpture's surface.\",\n",
    "    \"The children ran screaming through the sprinkler.\",\n",
    "    # performative (12)\n",
    "    \"Run the idea by me again.\",\n",
    "    \"Let the engine run for five minutes.\",\n",
    "    \"Run for your life!\",\n",
    "    \"She decided to run the experiment again.\",\n",
    "    \"They‚Äôre running a sale on electronics this weekend.\",\n",
    "    \"She‚Äôs running for president of the council.\",\n",
    "    \"The manager ran the meeting efficiently.\",\n",
    "    \"He used to run track in college.\",\n",
    "    \"They run a family-owned bakery downtown.\",\n",
    "    \"He decided to run for office in the next election.\",\n",
    "    \"Please run this report by end of day.\",\n",
    "    \"Run the installer before rebooting.\"\n",
    "]\n",
    "# üß† Matching semantic function per sentence\n",
    "semantic_functions = (\n",
    "    [\"descriptive\"] * 12 +\n",
    "    [\"evaluative\"] * 12 +\n",
    "    [\"narrative\"] * 12 +\n",
    "    [\"performative\"] * 12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888632d",
   "metadata": {},
   "source": [
    "## 2. BERT Trajectory Extraction\n",
    "We extract the contextual embedding of each 'run' token across 12 BERT layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b67d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch, numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "model.eval()\n",
    "\n",
    "trajectories = []\n",
    "valid_sentences = []\n",
    "\n",
    "print(\"üîç Matching token: 'run'\")\n",
    "\n",
    "for sent in tqdm(sentences):\n",
    "    inputs = tokenizer(sent, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    input_ids = inputs[\"input_ids\"][0]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    print(f\"üßæ Sentence: {sent}\")\n",
    "    print(f\"üî§ Tokens: {tokens}\")\n",
    "\n",
    "    match_indices = [i for i, tok in enumerate(tokens) if \"run\" in tok.lower()]\n",
    "    if not match_indices:\n",
    "        print(\"‚ö†Ô∏è No 'run' token found ‚Äî skipping.\")\n",
    "        continue\n",
    "\n",
    "    idx = match_indices[0]\n",
    "    layers = outputs.hidden_states\n",
    "    curve = torch.stack([layer[0, idx] for layer in layers])  # shape: (13, 768)\n",
    "    curve = curve[-12:]  # last 12 layers only\n",
    "\n",
    "    if curve.shape == (12, 768):\n",
    "        trajectories.append(curve.numpy())\n",
    "        valid_sentences.append(sent)\n",
    "    else:\n",
    "        print(\"‚ùå Unexpected shape ‚Äî skipping.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Extracted {len(trajectories)} valid trajectories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4630064",
   "metadata": {},
   "source": [
    "## 3. PCA Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76cee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "flat = np.stack(trajectories).reshape(len(trajectories), -1)\n",
    "pca = PCA(n_components=30)\n",
    "reduced = pca.fit_transform(flat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eae27aa",
   "metadata": {},
   "source": [
    "## 4. Scree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Scree Plot')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366333f",
   "metadata": {},
   "source": [
    "## 5. UMAP Projection + DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3193ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from sklearn.cluster import DBSCAN\n",
    "umap = UMAP(n_components=3)\n",
    "embed = umap.fit_transform(flat)\n",
    "db = DBSCAN(eps=0.8, min_samples=3)\n",
    "labels = db.fit_predict(embed)\n",
    "print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bada86",
   "metadata": {},
   "source": [
    "## 6. Visualize UMAP Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "sc = ax.scatter(embed[:,0], embed[:,1], embed[:,2], c=labels, cmap='tab10')\n",
    "plt.legend(*sc.legend_elements(), title=\"Cluster\")\n",
    "plt.title(\"UMAP + DBSCAN Clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7fdddc",
   "metadata": {},
   "source": [
    "## 7. Cluster to Function Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df1c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚õ≥ Make sure this matches the filtered trajectories\n",
    "valid_funcs = [semantic_functions[i] for i, traj in enumerate(trajectories) if traj.shape == (12, 768)]\n",
    "\n",
    "# üß≠ Map functions to clusters\n",
    "from collections import defaultdict\n",
    "cluster_map = defaultdict(list)\n",
    "\n",
    "for i, lbl in enumerate(labels):\n",
    "    if i < len(valid_funcs):\n",
    "        cluster_map[lbl].append(valid_funcs[i])\n",
    "\n",
    "# üñ®Ô∏è Print function composition of each cluster\n",
    "for cl, fs in cluster_map.items():\n",
    "    print(f\"\\nüîπ Cluster {cl}:\")\n",
    "    for func in sorted(set(fs)):\n",
    "        print(f\"  {func}: {fs.count(func)} / {len(fs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a62990-b2ed-446a-966c-7bd1e96d264d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
